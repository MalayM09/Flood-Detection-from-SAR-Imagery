{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jr7xYcInB9B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import rasterio\n",
        "\n",
        "def lee_filter(img, size=7):\n",
        "    img_mean = cv2.blur(img, (size, size))\n",
        "    img_sqr_mean = cv2.blur(img**2, (size, size))\n",
        "    img_variance = img_sqr_mean - img_mean**2\n",
        "    overall_variance = np.var(img)\n",
        "    img_weights = img_variance / (img_variance + overall_variance + 1e-8)\n",
        "    img_filtered = img_mean + img_weights * (img - img_mean)\n",
        "    return img_filtered\n",
        "\n",
        "def extract_key(filename):\n",
        "    name = os.path.basename(filename).lower()\n",
        "    if any(city in name for city in ['gorakhpur', 'chennai', 'brahmaputra']):\n",
        "        if 'mask' in name:\n",
        "            match = re.search(r'sen_\\w+_mask_(\\d+)', name)\n",
        "            return f'divit_{match.group(1)}' if match else None\n",
        "        else:\n",
        "            match = re.search(r'sen_\\w+_(\\d{8})_(\\d+)', name)\n",
        "            return f'divit_{match.group(2)}' if match else None\n",
        "    if re.match(r'sen_gj_\\d{4}_', name):\n",
        "        match = re.search(r'sen_(\\w{2})_(\\d{4})', name)\n",
        "        if match:\n",
        "            state, tile = match.groups()\n",
        "            return f\"{state}_{tile}\"\n",
        "    match_vijay2 = re.search(r'sen_(\\w{2})_(\\d{6})_(\\d{4})', name)\n",
        "    if match_vijay2:\n",
        "        state, _, tile = match_vijay2.groups()\n",
        "        return f\"{state}_{tile}\"\n",
        "    match_vijay = re.search(r'sen_(\\w{2})_(\\d{4})_\\d{4}', name)\n",
        "    if match_vijay:\n",
        "        state, tile = match_vijay.groups()\n",
        "        return f\"{state}_{tile}\"\n",
        "    match_general = re.search(r'sen_(\\w{2})_\\d{8}_(\\d{4})', name)\n",
        "    if match_general:\n",
        "        state, tile = match_general.groups()\n",
        "        return f\"{state}_{tile}\"\n",
        "    return None\n",
        "\n",
        "def load_dataset(base_dir, target_size=(256, 256)):\n",
        "    before_folder = os.path.join(base_dir, 'before_geotiff')\n",
        "    after_folder = os.path.join(base_dir, 'after_geotiff')\n",
        "    mask_folder = os.path.join(base_dir, 'masked_geotiff')\n",
        "    before_images = sorted(glob.glob(os.path.join(before_folder, '*.tif')))\n",
        "    after_images = sorted(glob.glob(os.path.join(after_folder, '*.tif')))\n",
        "    mask_images = sorted(glob.glob(os.path.join(mask_folder, '*.tif')))\n",
        "    before_dict = {extract_key(f): f for f in before_images if extract_key(f)}\n",
        "    after_dict = {extract_key(f): f for f in after_images if extract_key(f)}\n",
        "    mask_dict = {extract_key(f): f for f in mask_images if extract_key(f)}\n",
        "    paired_data = []\n",
        "    for key in before_dict:\n",
        "        if key in after_dict and key in mask_dict:\n",
        "            paired_data.append((before_dict[key], after_dict[key], mask_dict[key]))\n",
        "    print(f\"âœ… Total Paired Samples: {len(paired_data)}\")\n",
        "    return paired_data\n",
        "\n",
        "def preprocess_sar_image_tiff(img_path, target_size=(256, 256), apply_lee=True):\n",
        "    with rasterio.open(img_path) as src:\n",
        "        img = src.read(1).astype(np.float32)\n",
        "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "    if apply_lee:\n",
        "        img = lee_filter(img)\n",
        "        img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "    img = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
        "    img = np.stack([img]*3, axis=-1)\n",
        "    return img\n",
        "\n",
        "def preprocess_and_save_npz(\n",
        "    paired_data, output_path, target_size=(256, 256),\n",
        "    apply_lee=True, mask_threshold=50, dilate_mask=True\n",
        "):\n",
        "    before_list, after_list, mask_list = [], [], []\n",
        "    all_zero_count = 0\n",
        "    for idx, (before_path, after_path, mask_path) in enumerate(paired_data):\n",
        "        before_img = preprocess_sar_image_tiff(before_path, target_size, apply_lee)\n",
        "        after_img = preprocess_sar_image_tiff(after_path, target_size, apply_lee)\n",
        "        with rasterio.open(mask_path) as src:\n",
        "            mask_arr = src.read(1)\n",
        "        mask_arr = cv2.resize(mask_arr, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "        bin_mask = (mask_arr > mask_threshold).astype(np.uint8)\n",
        "        if dilate_mask:\n",
        "            bin_mask = cv2.dilate(bin_mask, np.ones((3,3), np.uint8), iterations=1)\n",
        "        if np.all(bin_mask == 0):\n",
        "            all_zero_count += 1\n",
        "            print(f\"Warning: All-zero mask for {mask_path}\")\n",
        "        before_list.append(before_img)\n",
        "        after_list.append(after_img)\n",
        "        mask_list.append(bin_mask)\n",
        "    before_np = np.stack(before_list)\n",
        "    after_np = np.stack(after_list)\n",
        "    mask_np = np.stack(mask_list)\n",
        "    np.savez_compressed(output_path, before=before_np, after=after_np, mask=mask_np)\n",
        "    print(f\"Saved .npz file to {output_path}\")\n",
        "    print(f\"Total all-zero masks: {all_zero_count} out of {len(mask_list)}\")\n",
        "\n",
        "base_dir = \"/kaggle/working\"\n",
        "paired_data = load_dataset(base_dir)\n",
        "preprocess_and_save_npz(\n",
        "    paired_data,\n",
        "    \"flood_data.npz\",\n",
        "    target_size=(256, 256),\n",
        "    apply_lee=True,\n",
        "    mask_threshold=50,      # Keep threshold at 50 as you requested\n",
        "    dilate_mask=True        # Apply dilation to preserve thin regions\n",
        ")\n",
        "\n",
        "def visualize_masks(npz_path, num_samples=5):\n",
        "    data = np.load(npz_path)\n",
        "    masks = data['mask']\n",
        "    total = len(masks)\n",
        "    all_zero_count = 0\n",
        "    for i in range(num_samples):\n",
        "        idx = random.randint(0, total-1)\n",
        "        mask = masks[idx]\n",
        "        percent_fg = 100 * (mask > 0).sum() / mask.size\n",
        "        if np.all(mask == 0):\n",
        "            all_zero_count += 1\n",
        "        print(f\"Sample {idx}: Foreground pixels = {percent_fg:.2f}%\")\n",
        "        plt.imshow(mask, cmap='gray')\n",
        "        plt.title(f\"Mask {idx} - Foreground: {percent_fg:.2f}%\")\n",
        "        plt.show()\n",
        "    print(f\"Total all-zero masks in visualization: {all_zero_count} out of {num_samples}\")\n",
        "\n",
        "visualize_masks(\"flood_data.npz\", num_samples=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "import random\n",
        "\n",
        "data = np.load(\"flood_data.npz\")\n",
        "before_dataset = data['before']\n",
        "after_dataset = data['after']\n",
        "mask_dataset = data['mask']\n",
        "\n",
        "def to_tensor_channel_first(img):\n",
        "    if img.ndim == 3:\n",
        "        img = np.transpose(img, (2, 0, 1))\n",
        "    return img.astype(np.float32)\n",
        "\n",
        "before_dataset = np.array([to_tensor_channel_first(img) for img in before_dataset])\n",
        "after_dataset = np.array([to_tensor_channel_first(img) for img in after_dataset])\n",
        "mask_dataset = np.array([img.astype(np.float32) for img in mask_dataset])\n",
        "\n",
        "combined_dataset = np.concatenate([before_dataset, after_dataset], axis=1)\n",
        "\n",
        "class FloodDataset(Dataset):\n",
        "    def __init__(self, X, y, augment=False, rotation_degrees=10):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.augment = augment\n",
        "        self.rotation_degrees = rotation_degrees\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        img = torch.tensor(self.X[idx], dtype=torch.float32)\n",
        "        mask = torch.tensor(self.y[idx], dtype=torch.float32).unsqueeze(0)\n",
        "        if self.augment and random.random() < 0.8:\n",
        "            angle = random.uniform(-self.rotation_degrees, self.rotation_degrees)\n",
        "            img = TF.rotate(img, angle, interpolation=TF.InterpolationMode.BILINEAR)\n",
        "            mask = TF.rotate(mask, angle, interpolation=TF.InterpolationMode.NEAREST)\n",
        "            if random.random() > 0.5:\n",
        "                img = TF.hflip(img)\n",
        "                mask = TF.hflip(mask)\n",
        "            if random.random() > 0.5:\n",
        "                img = TF.vflip(img)\n",
        "                mask = TF.vflip(mask)\n",
        "        return img, mask\n",
        "\n",
        "dataset = FloodDataset(combined_dataset, mask_dataset, augment=True, rotation_degrees=10)\n",
        "total = len(dataset)\n",
        "train_size = int(0.7 * total)\n",
        "val_size = int(0.15 * total)\n",
        "test_size = total - train_size - val_size\n",
        "\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size], generator=generator)\n",
        "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=8, pin_memory=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=8, pin_memory=True)\n",
        "\n",
        "# --- Focal Tversky Loss ---\n",
        "class FocalTverskyLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.7, beta=0.3, gamma=0.75, smooth=1e-6):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "        self.smooth = smooth\n",
        "    def forward(self, pred, target):\n",
        "        pred = torch.sigmoid(pred)\n",
        "        tp = (pred * target).sum()\n",
        "        fp = ((1 - target) * pred).sum()\n",
        "        fn = (target * (1 - pred)).sum()\n",
        "        tversky = (tp + self.smooth) / (tp + self.alpha * fp + self.beta * fn + self.smooth)\n",
        "        return torch.pow((1 - tversky), self.gamma)\n",
        "\n",
        "loss_fn = FocalTverskyLoss(alpha=0.7, beta=0.3, gamma=0.75)\n",
        "\n",
        "def dice_score(pred, target, smooth=1e-6):\n",
        "    pred = torch.sigmoid(pred)\n",
        "    pred = (pred > 0.5).float()\n",
        "    target = target.float()\n",
        "    intersection = (pred * target).sum(dim=(1,2,3))\n",
        "    union = pred.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3))\n",
        "    dice = (2 * intersection + smooth) / (union + smooth)\n",
        "    return dice.mean().item()\n",
        "\n",
        "# --- UNet++ Model (unchanged, but see below for deeper model option) ---\n",
        "class UNetPlusPlus(nn.Module):\n",
        "    def __init__(self, in_channels=6, out_channels=1, deep_supervision=True):\n",
        "        super(UNetPlusPlus, self).__init__()\n",
        "        self.deep_supervision = deep_supervision\n",
        "        def conv_block(in_c, out_c):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_c, out_c, 3, padding=1),\n",
        "                nn.BatchNorm2d(out_c),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_c, out_c, 3, padding=1),\n",
        "                nn.BatchNorm2d(out_c),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv0_0 = conv_block(in_channels, 64)\n",
        "        self.conv1_0 = conv_block(64, 128)\n",
        "        self.conv2_0 = conv_block(128, 256)\n",
        "        self.conv3_0 = conv_block(256, 512)\n",
        "        self.conv4_0 = conv_block(512, 1024)\n",
        "        self.up1_0 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.up2_0 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.up3_0 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
        "        self.up4_0 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
        "        self.conv0_1 = conv_block(64+64, 64)\n",
        "        self.conv1_1 = conv_block(128+128, 128)\n",
        "        self.conv2_1 = conv_block(256+256, 256)\n",
        "        self.conv3_1 = conv_block(512+512, 512)\n",
        "        self.up1_1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.up2_1 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.up3_1 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
        "        self.conv0_2 = conv_block(64*3, 64)\n",
        "        self.conv1_2 = conv_block(128*3, 128)\n",
        "        self.conv2_2 = conv_block(256*3, 256)\n",
        "        self.up1_2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.up2_2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.conv0_3 = conv_block(64*4, 64)\n",
        "        self.conv1_3 = conv_block(128*4, 128)\n",
        "        self.up1_3 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.conv0_4 = conv_block(64*5, 64)\n",
        "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        x0_0 = self.conv0_0(x)\n",
        "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
        "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up1_0(x1_0)], 1))\n",
        "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
        "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up2_0(x2_0)], 1))\n",
        "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up1_1(x1_1)], 1))\n",
        "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
        "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up3_0(x3_0)], 1))\n",
        "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up2_1(x2_1)], 1))\n",
        "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up1_2(x1_2)], 1))\n",
        "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
        "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up4_0(x4_0)], 1))\n",
        "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up3_1(x3_1)], 1))\n",
        "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up2_2(x2_2)], 1))\n",
        "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up1_3(x1_3)], 1))\n",
        "        output = self.final(x0_4)\n",
        "        return output\n",
        "\n",
        "# --- For a deeper model with ResNet encoder, use segmentation_models_pytorch ---\n",
        "# import segmentation_models_pytorch as smp\n",
        "# model = smp.UnetPlusPlus(encoder_name=\"resnet34\", in_channels=6, classes=1, encoder_weights=None).to(device)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNetPlusPlus(in_channels=6, out_channels=1).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "scaler = GradScaler()\n",
        "model_path = \"flood_segmentation_unetplusplus_train.pth\"\n",
        "\n",
        "def save_model(model, optimizer, path):\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, path)\n",
        "    print(f\"Model saved to {path}\")\n",
        "\n",
        "best_dice = 0.500\n",
        "num_epochs = 40  # Train for more epochs as recommended\n",
        "\n",
        "def train_epoch(model, loader, optimizer, loss_fn, scaler):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_dice = 0.0\n",
        "    for images, masks in loader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            preds = model(images)\n",
        "            loss = loss_fn(preds, masks)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item()\n",
        "        running_dice += dice_score(preds, masks)\n",
        "    return running_loss / len(loader), running_dice / len(loader)\n",
        "\n",
        "def validate(model, loader, loss_fn):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_dice = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, masks in loader:\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            preds = model(images)\n",
        "            loss = loss_fn(preds, masks)\n",
        "            running_loss += loss.item()\n",
        "            running_dice += dice_score(preds, masks)\n",
        "    return running_loss / len(loader), running_dice / len(loader)\n",
        "\n",
        "print(\"Starting training from scratch...\")\n",
        "train_losses, val_losses = [], []\n",
        "train_dices, val_dices = [], []\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_dice = train_epoch(model, train_loader, optimizer, loss_fn, scaler)\n",
        "    val_loss, val_dice = validate(model, val_loader, loss_fn)\n",
        "    train_losses.append(train_loss)\n",
        "    train_dices.append(train_dice)\n",
        "    val_losses.append(val_loss)\n",
        "    val_dices.append(val_dice)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Dice: {train_dice:.4f}\")\n",
        "    print(f\"Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}\")\n",
        "    if val_dice > best_dice:\n",
        "        best_dice = val_dice\n",
        "        save_model(model, optimizer, model_path)\n",
        "        print(f\"New best model saved with Dice: {best_dice:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Val Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss over epochs')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_dices, label='Train Dice')\n",
        "plt.plot(val_dices, label='Val Dice')\n",
        "plt.legend()\n",
        "plt.title('Dice Score over epochs')\n",
        "plt.show()\n",
        "\n",
        "test_loss, test_dice = validate(model, test_loader, loss_fn)\n",
        "print(f\"\\nFinal Test Results:\")\n",
        "print(f\"Test Loss: {test_loss:.4f} | Test Dice: {test_dice:.4f}\")\n",
        "\n",
        "def visualize_predictions(model, loader, num_samples=5):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (images, masks) in enumerate(loader):\n",
        "            if i >= num_samples:\n",
        "                break\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            preds = torch.sigmoid(model(images))\n",
        "            preds_bin = (preds > 0.5).float()\n",
        "            img_np = images[0, :3].cpu().numpy().transpose(1, 2, 0)\n",
        "            after_np = images[0, 3:6].cpu().numpy().transpose(1, 2, 0)\n",
        "            mask_np = masks[0, 0].cpu().numpy()\n",
        "            pred_np = preds_bin[0, 0].cpu().numpy()\n",
        "            fg_pct = 100 * pred_np.sum() / pred_np.size\n",
        "            print(f\"Predicted mask {i}: {fg_pct:.2f}% foreground\")\n",
        "            plt.figure(figsize=(18, 5))\n",
        "            plt.subplot(1, 4, 1)\n",
        "            plt.imshow(img_np)\n",
        "            plt.title('Before RGB')\n",
        "            plt.subplot(1, 4, 2)\n",
        "            plt.imshow(after_np)\n",
        "            plt.title('After RGB')\n",
        "            plt.subplot(1, 4, 3)\n",
        "            plt.imshow(mask_np, cmap='gray')\n",
        "            plt.title('Ground Truth')\n",
        "            plt.subplot(1, 4, 4)\n",
        "            plt.imshow(pred_np, cmap='gray')\n",
        "            plt.title('Prediction')\n",
        "            plt.show()\n",
        "\n",
        "visualize_predictions(model, test_loader, num_samples=5)\n",
        "\n",
        "# ---- Tiny Set Overfitting (disable augmentation for tiny set) ----\n",
        "tiny_ds = torch.utils.data.Subset(FloodDataset(combined_dataset, mask_dataset, augment=False), range(10))\n",
        "tiny_loader = DataLoader(tiny_ds, batch_size=2, shuffle=True)\n",
        "tiny_model = UNetPlusPlus(in_channels=6, out_channels=1).to(device)\n",
        "tiny_optimizer = torch.optim.Adam(tiny_model.parameters(), lr=1e-3)\n",
        "tiny_scaler = GradScaler()\n",
        "tiny_loss_fn = FocalTverskyLoss(alpha=0.7, beta=0.3, gamma=0.75)\n",
        "for epoch in range(20):\n",
        "    train_loss, train_dice = train_epoch(tiny_model, tiny_loader, tiny_optimizer, tiny_loss_fn, tiny_scaler)\n",
        "    print(f\"Tiny set Epoch {epoch+1}: Loss {train_loss:.4f}, Dice {train_dice:.4f}\")\n"
      ],
      "metadata": {
        "id": "4fxAfRYvnJJr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}